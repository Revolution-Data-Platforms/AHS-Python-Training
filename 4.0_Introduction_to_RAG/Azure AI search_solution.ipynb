{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up the Azure OpenAI Client\n",
    "1. **Importing Libraries**: We import the necessary libraries including `openai` for interacting with the Azure OpenAI API and `dotenv` for loading environment variables from a `.env` file.\n",
    "2. **Loading Environment Variables**: We load the API key, API version, and Azure endpoint from the `.env` file using `load_dotenv()` to ensure secure and dynamic configuration.\n",
    "3. **Initializing Azure Client**: We create an instance of the `AzureOpenAI` client using the loaded environment variables.\n",
    "4. **Environment Check**: To verify that everything is set up properly, we print the API key, version, and endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "import json\n",
    "import re\n",
    "import PyPDF2 \n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('variables.env')\n",
    "# Azure OpenAI configuration\n",
    "azure_openai_api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "azure_openai_api_version = os.getenv('AZURE_OPENAI_API_VERSION')\n",
    "azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "service_name = os.getenv('AZURE_SERVICE_NAME') \n",
    "admin_key = os.getenv('AZURE_ADMIN_KEY')  \n",
    "endpoint = f\"https://{service_name}.search.windows.net\"\n",
    "openai_deployment = \"gpt-4o\"  # Replace with your model deployment name\n",
    "\n",
    "print(azure_openai_api_key)\n",
    "print(azure_openai_api_version)\n",
    "print(azure_endpoint)\n",
    "print(service_name)\n",
    "print(admin_key)\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ai Search Index Creation\n",
    "\n",
    "This cell creates an Azure Cognitive Search index for climate change documents.\n",
    "\n",
    "Key points:\n",
    "- Sets up index schema with fields for id, content, and chapter\n",
    "- Uses REST API to create the index\n",
    "- Prints success message if index is created, error details if it fails\n",
    "\n",
    "Note: Ensure `admin_key` and `endpoint` are correctly set before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Index name\n",
    "index_name = \"climate-change-index\"\n",
    "\n",
    "# Headers for REST API calls\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'api-key': admin_key\n",
    "}\n",
    "\n",
    "# Updated Index schema\n",
    "index_schema = {\n",
    "    \"name\": index_name,\n",
    "    \"fields\": [\n",
    "        {\"name\": \"id\", \"type\": \"Edm.String\", \"key\": True, \"filterable\": True},\n",
    "        {\"name\": \"content\", \"type\": \"Edm.String\", \"searchable\": True, \"filterable\": False, \"sortable\": False, \"facetable\": False},\n",
    "        {\"name\": \"chapter\", \"type\": \"Edm.String\", \"filterable\": True, \"sortable\": True, \"facetable\": True}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create index\n",
    "create_index_url = f\"{endpoint}/indexes/{index_name}?api-version=2020-06-30\"\n",
    "response = requests.put(create_index_url, headers=headers, json=index_schema)\n",
    "\n",
    "if response.status_code == 201:\n",
    "    print(f\"Index '{index_name}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to create index. Status code: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Text Extraction\n",
    "\n",
    "This cell extracts text from a PDF file using PyPDF2.\n",
    "\n",
    "Key operations:\n",
    "- Defines a function to read and extract text from PDF\n",
    "- Extracts text from \"Understanding_Climate_Change.pdf\"\n",
    "- Prints a preview of the extracted text (first 500 characters)\n",
    "- Saves the full extracted text to \"extracted_text.txt\"\n",
    "\n",
    "Note: Ensure the PDF file path is correct before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Path to your PDF file\n",
    "pdf_path = \"./data/Understanding_Climate_Change.pdf\"  # Replace with the actual path to your PDF file\n",
    "\n",
    "# Extract text from the PDF\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Print the first 500 characters to verify the extraction\n",
    "print(\"Extracted text preview (first 500 characters):\")\n",
    "print(pdf_text[:500] + \"...\")\n",
    "\n",
    "# Save the extracted text to a file (optional, but useful for verification)\n",
    "with open(\"extracted_text.txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(pdf_text)\n",
    "\n",
    "print(f\"\\nFull text has been saved to 'extracted_text.txt'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Chunking and Document Upload\n",
    "\n",
    "This cell processes the extracted PDF text and uploads it to Azure Cognitive Search.\n",
    "\n",
    "Key operations:\n",
    "- Chunks the content into smaller segments\n",
    "- Extracts chapter information\n",
    "- Creates documents with ID, content, and chapter\n",
    "- Uploads the documents to the search index\n",
    "\n",
    "Note: Ensure the 'content' variable contains the actual PDF text before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def chunk_content(text, max_chunk_size=5000):\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    for line in text.split('\\n'):\n",
    "        if len(current_chunk) + len(line) > max_chunk_size:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = line\n",
    "        else:\n",
    "            current_chunk += \" \" + line\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    return chunks\n",
    "\n",
    "def extract_chapters(text):\n",
    "    chapters = re.findall(r'Chapter \\d+: .+', text)\n",
    "    return chapters\n",
    "\n",
    "# Assuming 'content' is the variable containing your PDF text\n",
    "content = \"\"\"Your PDF content goes here\"\"\"  # Replace this with your actual PDF content\n",
    "\n",
    "chapters = extract_chapters(content)\n",
    "chunked_content = chunk_content(content)\n",
    "\n",
    "documents = []\n",
    "for i, chunk in enumerate(chunked_content):\n",
    "    chapter = next((ch for ch in chapters if ch in chunk), \"Unknown Chapter\")\n",
    "    doc = {\n",
    "        \"id\": f\"doc{i}\",\n",
    "        \"content\": chunk,\n",
    "        \"chapter\": chapter\n",
    "    }\n",
    "    documents.append(doc)\n",
    "\n",
    "# Upload documents\n",
    "upload_url = f\"{endpoint}/indexes/{index_name}/docs/index?api-version=2020-06-30\"\n",
    "response = requests.post(upload_url, headers=headers, json={\"value\": documents})\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Documents uploaded successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to upload documents. Status code: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Verification\n",
    "\n",
    "This cell verifies the content uploaded to Azure Cognitive Search.\n",
    "\n",
    "Key operations:\n",
    "- Defines functions to:\n",
    "  - Get total document count\n",
    "  - Retrieve a sample of documents\n",
    "- Prints total document count\n",
    "- Displays sample documents with ID and chapter\n",
    "\n",
    "Note: This helps confirm successful upload and indexing of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Function to get document count\n",
    "def get_document_count():\n",
    "    count_url = f\"{endpoint}/indexes/{index_name}/docs/$count?api-version=2020-06-30\"\n",
    "    response = requests.get(count_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return int(response.text)\n",
    "    else:\n",
    "        print(f\"Failed to get document count. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Function to get a sample of documents\n",
    "def get_sample_documents(sample_size=5):\n",
    "    search_url = f\"{endpoint}/indexes/{index_name}/docs?api-version=2020-06-30\"\n",
    "    params = {\n",
    "        'search': '*',\n",
    "        'top': sample_size,\n",
    "        'select': 'id,chapter'\n",
    "    }\n",
    "    response = requests.get(search_url, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['value']\n",
    "    else:\n",
    "        print(f\"Failed to get sample documents. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Verify content\n",
    "doc_count = get_document_count()\n",
    "if doc_count is not None:\n",
    "    print(f\"Total documents in the index: {doc_count}\")\n",
    "\n",
    "sample_docs = get_sample_documents()\n",
    "if sample_docs:\n",
    "    print(\"\\nSample documents:\")\n",
    "    for doc in sample_docs:\n",
    "        print(f\"ID: {doc['id']}, Chapter: {doc['chapter']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Search and Results Display\n",
    "\n",
    "This cell demonstrates searching the Azure Cognitive Search index.\n",
    "\n",
    "Key operations:\n",
    "- Defines a function to search documents with highlighting\n",
    "- Performs test searches on climate change topics\n",
    "- Displays search results including:\n",
    "  - Document ID\n",
    "  - Chapter\n",
    "  - Highlighted relevant content\n",
    "\n",
    "Note: This showcases the search functionality and result presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def search_documents(query, top=3):\n",
    "    search_url = f\"{endpoint}/indexes/{index_name}/docs/search?api-version=2020-06-30\"\n",
    "    body = {\n",
    "        \"search\": query,\n",
    "        \"top\": top,\n",
    "        \"select\": \"id,chapter,content\",\n",
    "        \"highlight\": \"content\"\n",
    "    }\n",
    "    response = requests.post(search_url, headers=headers, json=body)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['value']\n",
    "    else:\n",
    "        print(f\"Search failed. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Test searches\n",
    "test_queries = [\n",
    "    \"climate change impacts\",\n",
    "    \"renewable energy solutions\",\n",
    "    \"carbon capture technologies\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nSearching for: {query}\")\n",
    "    results = search_documents(query)\n",
    "    if results:\n",
    "        for result in results:\n",
    "            print(f\"\\nID: {result['id']}\")\n",
    "            print(f\"Chapter: {result['chapter']}\")\n",
    "            print(f\"Relevant content: {result.get('@search.highlights', {}).get('content', ['No highlight'])[0]}\")\n",
    "    else:\n",
    "        print(\"No results found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Rechunking and Reindexing\n",
    "\n",
    "This cell improves the document chunking process and reindexes the content.\n",
    "\n",
    "Key operations:\n",
    "- Redefines chunking function to preserve chapter information\n",
    "- Loads extracted PDF text from file\n",
    "- Creates new documents with improved chapter tracking\n",
    "- Uploads rechunked documents to the search index\n",
    "\n",
    "Note: This process enhances the organization and searchability of the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def chunk_content(text, max_chunk_size=5000):\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    current_chapter = \"Unknown Chapter\"\n",
    "    \n",
    "    for line in text.split('\\n'):\n",
    "        if line.strip().startswith(\"Chapter\"):\n",
    "            if current_chunk:\n",
    "                chunks.append((current_chapter, current_chunk.strip()))\n",
    "            current_chunk = line\n",
    "            current_chapter = line.strip()\n",
    "        elif len(current_chunk) + len(line) > max_chunk_size:\n",
    "            chunks.append((current_chapter, current_chunk.strip()))\n",
    "            current_chunk = line\n",
    "        else:\n",
    "            current_chunk += \" \" + line\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append((current_chapter, current_chunk.strip()))\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Load the extracted PDF text\n",
    "with open(\"extracted_text.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    pdf_content = file.read()\n",
    "\n",
    "chunked_content = chunk_content(pdf_content)\n",
    "\n",
    "documents = []\n",
    "for i, (chapter, chunk) in enumerate(chunked_content):\n",
    "    doc = {\n",
    "        \"id\": f\"doc{i}\",\n",
    "        \"content\": chunk,\n",
    "        \"chapter\": chapter\n",
    "    }\n",
    "    documents.append(doc)\n",
    "\n",
    "# Upload documents\n",
    "upload_url = f\"{endpoint}/indexes/{index_name}/docs/index?api-version=2020-06-30\"\n",
    "response = requests.post(upload_url, headers=headers, json={\"value\": documents})\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(f\"Successfully reindexed {len(documents)} documents.\")\n",
    "else:\n",
    "    print(f\"Failed to reindex documents. Status code: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Pipeline Implementation\n",
    "\n",
    "This cell implements a Retrieval-Augmented Generation (RAG) pipeline for climate change questions.\n",
    "\n",
    "Key components:\n",
    "- Document retrieval from Azure Cognitive Search\n",
    "- Prompt creation using retrieved documents\n",
    "- Response generation using Azure OpenAI\n",
    "\n",
    "Features:\n",
    "- Utilizes both search and OpenAI APIs\n",
    "- Creates context-aware prompts\n",
    "- Implements an interactive Q&A loop\n",
    "\n",
    "Note: Ensure all API keys and endpoints are correctly set before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search_headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'api-key': admin_key\n",
    "}\n",
    "\n",
    "openai_headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'api-key': azure_openai_api_key\n",
    "}\n",
    "\n",
    "def retrieve_documents(query: str, top: int = 3) -> List[Dict]:\n",
    "    search_url = f\"{endpoint}/indexes/{index_name}/docs/search?api-version=2020-06-30\"\n",
    "    body = {\n",
    "        \"search\": query,\n",
    "        \"top\": top,\n",
    "        \"select\": \"content,chapter\",\n",
    "        \"highlight\": \"content\"\n",
    "    }\n",
    "    response = requests.post(search_url, headers=search_headers, json=body)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['value']\n",
    "    else:\n",
    "        print(f\"Search failed. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "def create_prompt(query: str, docs: List[Dict]) -> str:\n",
    "    context = \"\\n\\n\".join([f\"Chapter: {doc['chapter']}\\nContent: {doc['content']}\" for doc in docs])\n",
    "    return f\"\"\"You are an AI assistant specializing in climate change. Use the following information to answer the user's question. If you can't answer the question based on the provided information, say so.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "def generate_response(prompt: str) -> str:\n",
    "    url = f\"{azure_endpoint}/openai/deployments/{openai_deployment}/chat/completions?api-version=2023-05-15\"\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions about climate change.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": 150,\n",
    "        \"temperature\": 0.7,\n",
    "        \"n\": 1\n",
    "    }\n",
    "    response = requests.post(url, headers=openai_headers, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['choices'][0]['message']['content'].strip()\n",
    "    else:\n",
    "        print(f\"OpenAI API request failed. Status code: {response.status_code}\")\n",
    "        return \"Sorry, I couldn't generate a response at this time.\"\n",
    "\n",
    "def rag_pipeline(query: str) -> str:\n",
    "    # Retrieve relevant documents\n",
    "    docs = retrieve_documents(query)\n",
    "    \n",
    "    # Create prompt\n",
    "    prompt = create_prompt(query, docs)\n",
    "    \n",
    "    # Generate response\n",
    "    response = generate_response(prompt)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        user_query = input(\"Enter your question about climate change (or 'quit' to exit): \")\n",
    "        if user_query.lower() == 'quit':\n",
    "            break\n",
    "        \n",
    "        answer = rag_pipeline(user_query)\n",
    "        print(f\"\\nAnswer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced RAG Pipeline with Customization Options\n",
    "\n",
    "This cell implements an advanced Retrieval-Augmented Generation (RAG) pipeline for climate change queries.\n",
    "\n",
    "Key features:\n",
    "- Flexible document retrieval from Azure Cognitive Search\n",
    "- Customizable prompt styles (default, detailed, concise)\n",
    "- Adjustable response length with max_tokens\n",
    "- Interactive user input for query parameters\n",
    "\n",
    "Components:\n",
    "- Document retrieval function\n",
    "- Dynamic prompt creation based on style\n",
    "- Azure OpenAI integration for response generation\n",
    "- Main loop for continuous user interaction\n",
    "\n",
    "Note: Ensure all API keys and endpoints are correctly configured before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search_headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'api-key': admin_key\n",
    "}\n",
    "\n",
    "openai_headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'api-key': azure_openai_api_key\n",
    "}\n",
    "\n",
    "def retrieve_documents(query: str, top: int = 3) -> List[Dict]:\n",
    "    search_url = f\"{endpoint}/indexes/{index_name}/docs/search?api-version=2020-06-30\"\n",
    "    body = {\n",
    "        \"search\": query,\n",
    "        \"top\": top,\n",
    "        \"select\": \"content,chapter\",\n",
    "        \"highlight\": \"content\"\n",
    "    }\n",
    "    response = requests.post(search_url, headers=search_headers, json=body)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['value']\n",
    "    else:\n",
    "        print(f\"Search failed. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "def create_prompt(query: str, docs: List[Dict], prompt_style: str = \"default\") -> str:\n",
    "    context = \"\\n\\n\".join([f\"Chapter: {doc['chapter']}\\nContent: {doc['content']}\" for doc in docs])\n",
    "    \n",
    "    if prompt_style == \"detailed\":\n",
    "        return f\"\"\"You are an AI assistant specializing in climate change. Use the following information to answer the user's question. If you can't answer the question based on the provided information, say so. Provide a detailed explanation and, if possible, include specific examples or data from the context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User Question: {query}\n",
    "\n",
    "Detailed Answer:\"\"\"\n",
    "    \n",
    "    elif prompt_style == \"concise\":\n",
    "        return f\"\"\"You are an AI assistant specializing in climate change. Provide a brief and concise answer to the user's question based on the following information. If you can't answer the question based on the provided information, say so briefly.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User Question: {query}\n",
    "\n",
    "Concise Answer:\"\"\"\n",
    "    \n",
    "    else:  # default prompt style\n",
    "        return f\"\"\"You are an AI assistant specializing in climate change. Use the following information to answer the user's question. If you can't answer the question based on the provided information, say so.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "def generate_response(prompt: str, max_tokens: int = 150) -> str:\n",
    "    url = f\"{azure_endpoint}/openai/deployments/{openai_deployment}/chat/completions?api-version=2023-05-15\"\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions about climate change.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": 0.7,\n",
    "        \"n\": 1\n",
    "    }\n",
    "    response = requests.post(url, headers=openai_headers, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['choices'][0]['message']['content'].strip()\n",
    "    else:\n",
    "        print(f\"OpenAI API request failed. Status code: {response.status_code}\")\n",
    "        return \"Sorry, I couldn't generate a response at this time.\"\n",
    "\n",
    "def rag_pipeline(query: str, num_docs: int = 3, prompt_style: str = \"default\", max_tokens: int = 150) -> str:\n",
    "    # Retrieve relevant documents\n",
    "    docs = retrieve_documents(query, num_docs)\n",
    "    \n",
    "    # Create prompt\n",
    "    prompt = create_prompt(query, docs, prompt_style)\n",
    "    \n",
    "    # Generate response``\n",
    "    response = generate_response(prompt, max_tokens)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        user_query = input(\"Enter your question about climate change (or 'quit' to exit): \")\n",
    "        if user_query.lower() == 'quit':\n",
    "            break\n",
    "        \n",
    "        num_docs = int(input(\"Enter the number of documents to retrieve (1-5): \"))\n",
    "        prompt_style = input(\"Enter prompt style (default/detailed/concise): \")\n",
    "        max_tokens = int(input(\"Enter maximum number of tokens for the response (50-500): \"))\n",
    "        \n",
    "        answer = rag_pipeline(user_query, num_docs, prompt_style, max_tokens)\n",
    "        print(f\"\\nAnswer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####    Perform a filtered search on the Azure AI Search index.\n",
    "\n",
    "  This function allows you to search for documents that match both a search query\n",
    "  and a specific filter condition. Filtering is useful for narrowing down search \n",
    "  results based on specific criteria.\n",
    "\n",
    "  Parameters:\n",
    "  - query (str): The search query string.\n",
    "  - filter_condition (str): An OData filter expression. This allows for complex\n",
    "    filtering based on field values. Examples include:\n",
    "    - \"id eq 'doc14'\"  # Exact match on id\n",
    "    - \"content/any(t: t eq 'climate')\"  # Check if 'climate' is in the content\n",
    "    - \"id ge 'doc10' and id le 'doc20'\"  # Range of document ids\n",
    "  - top (int, optional): The maximum number of results to return. Default is 10.\n",
    "\n",
    "  Returns:\n",
    "  - dict: A dictionary containing the search results if successful, None otherwise.\n",
    "    The 'value' key in the dictionary contains the list of matching documents.\n",
    "\n",
    "  Usage example:\n",
    "  result = filtered_search(\"climate change\", \"id eq 'doc14'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_search(query, filter_condition, top=10):\n",
    "    search_url = f\"{endpoint}/indexes/{index_name}/docs/search?api-version=2020-06-30\"\n",
    "    body = {\n",
    "        \"search\": query,\n",
    "        \"filter\": filter_condition,\n",
    "        \"top\": top,\n",
    "        \"select\": \"id,content\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(search_url, headers=headers, json=body)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        if hasattr(e, 'response'):\n",
    "            print(f\"Response status code: {e.response.status_code}\")\n",
    "            print(f\"Response content: {e.response.content}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "filter_condition = \"id eq 'doc14'\"  # Filter for a specific document\n",
    "result = filtered_search(\"climate change\", filter_condition)\n",
    "\n",
    "if result:\n",
    "    print(f\"Filtered search successful. Number of results: {len(result.get('value', []))}\")\n",
    "    for item in result.get('value', []):\n",
    "        print(f\"ID: {item.get('id')}\")\n",
    "        print(f\"Content snippet: {item.get('content')[:100]}...\")\n",
    "        print(\"---\")\n",
    "else:\n",
    "    print(\"Filtered search failed. Please check the error messages above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description:\n",
    "\n",
    "Purpose: Performs a search and returns faceted results.\n",
    "Parameters:\n",
    "\n",
    "query: The search term(s).\n",
    "facets: List of fields to facet on.\n",
    "top: Maximum number of results to return.\n",
    "\n",
    "\n",
    "Usage: Helpful for creating categorized search results, allowing users to drill down into specific categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faceted_search(query, facets, top=10):\n",
    "    search_url = f\"{endpoint}/indexes/{index_name}/docs/search?api-version=2020-06-30\"\n",
    "    body = {\n",
    "        \"search\": query,\n",
    "        \"facets\": facets,\n",
    "        \"top\": top,\n",
    "        \"select\": \"id,content\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(search_url, headers=headers, json=body)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        if hasattr(e, 'response'):\n",
    "            print(f\"Response status code: {e.response.status_code}\")\n",
    "            print(f\"Response content: {e.response.content}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "facets = [\"id\"]  # Using 'id' as a facet for demonstration\n",
    "result = faceted_search(\"climate change\", facets)\n",
    "\n",
    "if result:\n",
    "    print(f\"Faceted search successful. Number of results: {len(result.get('value', []))}\")\n",
    "    print(\"Facets:\")\n",
    "    for facet in result.get('@search.facets', {}).get('id', []):\n",
    "        print(f\"- {facet['value']}: {facet['count']}\")\n",
    "    print(\"\\nTop results:\")\n",
    "    for item in result.get('value', [])[:3]:\n",
    "        print(f\"ID: {item.get('id')}\")\n",
    "        print(f\"Content snippet: {item.get('content')[:100]}...\")\n",
    "        print(\"---\")\n",
    "else:\n",
    "    print(\"Faceted search failed. Please check the error messages above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description:\n",
    "\n",
    "Purpose: Performs a search and returns results with highlighted matching terms.\n",
    "Parameters:\n",
    "\n",
    "query: The search term(s).\n",
    "top: Maximum number of results to return.\n",
    "\n",
    "\n",
    "Usage: Enhances readability of search results by visually emphasizing the matched terms in the content.\n",
    "\n",
    "Each of these functions enhances the search experience in different ways:\n",
    "\n",
    "Filtered search allows for precise querying based on specific field values.\n",
    "Faceted search provides a way to categorize and navigate through search results.\n",
    "Highlighted search helps users quickly identify where their search terms appear in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlighted_search(query, top=10):\n",
    "    search_url = f\"{endpoint}/indexes/{index_name}/docs/search?api-version=2020-06-30\"\n",
    "    body = {\n",
    "        \"search\": query,\n",
    "        \"highlight\": \"content\",\n",
    "        \"highlightPreTag\": \"<em>\",\n",
    "        \"highlightPostTag\": \"</em>\",\n",
    "        \"top\": top,\n",
    "        \"select\": \"id,content\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(search_url, headers=headers, json=body)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        if hasattr(e, 'response'):\n",
    "            print(f\"Response status code: {e.response.status_code}\")\n",
    "            print(f\"Response content: {e.response.content}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "result = highlighted_search(\"climate change impacts\")\n",
    "\n",
    "if result:\n",
    "    print(f\"Highlighted search successful. Number of results: {len(result.get('value', []))}\")\n",
    "    for item in result.get('value', [])[:3]:\n",
    "        print(f\"ID: {item.get('id')}\")\n",
    "        print(\"Highlighted content:\")\n",
    "        for highlight in item.get('@search.highlights', {}).get('content', []):\n",
    "            print(f\"- {highlight}\")\n",
    "        print(\"---\")\n",
    "else:\n",
    "    print(\"Highlighted search failed. Please check the error messages above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # Azure AI Search UI Features and Example Queries\n",
    "\n",
    "Here's a list of features you can test in the Azure AI Search UI, along with example queries for each:\n",
    "\n",
    "1. Basic Full-Text Search:\n",
    "```\n",
    "search=climate change\n",
    "```\n",
    "\n",
    "2. Filtering:\n",
    "```\n",
    "search=climate&$filter=chapter eq 'Chapter 7: The Economics of Climate Change'\n",
    "```\n",
    "\n",
    "3. Sorting:\n",
    "```\n",
    "search=climate&$orderby=id desc\n",
    "```\n",
    "\n",
    "4. Faceting:\n",
    "```\n",
    "search=climate&$facet=chapter\n",
    "```\n",
    "\n",
    "5. Selecting Specific Fields:\n",
    "```\n",
    "search=climate&$select=id,chapter\n",
    "```\n",
    "\n",
    "6. Limiting Results:\n",
    "```\n",
    "search=climate&$top=5\n",
    "```\n",
    "\n",
    "7. Skipping Results (for pagination):\n",
    "```\n",
    "search=climate&$skip=10&$top=10\n",
    "```\n",
    "\n",
    "8. Highlighting:\n",
    "```\n",
    "search=climate&$highlight=content\n",
    "```\n",
    "\n",
    "9. Count:\n",
    "```\n",
    "search=climate&$count=true\n",
    "```\n",
    "\n",
    "10. Fuzzy Search:\n",
    "```\n",
    "search=climte~1\n",
    "```\n",
    "\n",
    "11. Wildcard Search:\n",
    "```\n",
    "search=clim*\n",
    "```\n",
    "\n",
    "12. Regular Expression:\n",
    "```\n",
    "search=/clim(ate|e)/\n",
    "```\n",
    "\n",
    "13. Search Multiple Fields:\n",
    "```\n",
    "search=climate change&searchFields=content,chapter\n",
    "```\n",
    "\n",
    "14. Boosting Fields:\n",
    "```\n",
    "search=climate^2 change\n",
    "```\n",
    "\n",
    "15. Complex Queries:\n",
    "```\n",
    "search=climate change&$filter=chapter eq 'Chapter 13: Climate Change and Social Justice'&$facet=id&$orderby=id&$select=id,chapter&$top=5&$highlight=content&$count=true\n",
    "```\n",
    "\n",
    "16. Semantic Search (if enabled):\n",
    "```\n",
    "search=impact of climate change on agriculture&queryType=semantic&semanticConfiguration=default\n",
    "```\n",
    "\n",
    "17. Autocomplete (if suggesters are configured):\n",
    "```\n",
    "/autocomplete?search=cli&suggesterName=sg\n",
    "```\n",
    "\n",
    "Remember to replace field names (like 'chapter') with the actual names in your index if they differ.\n",
    "\n",
    "## Tips for Testing:\n",
    "1. Start with simple queries and gradually add complexity.\n",
    "2. Pay attention to the JSON response to understand how each parameter affects the results.\n",
    "3. Use the 'Request URL' generated by the UI to understand how queries are constructed.\n",
    "4. Experiment with combining different features to see how they interact.\n",
    "\n",
    "## Note:\n",
    "Some features (like Semantic Search or Autocomplete) may require additional configuration in your search service. If these are not set up, the corresponding queries may not work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
