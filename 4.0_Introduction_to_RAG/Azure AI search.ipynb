{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up the Azure OpenAI Client\n",
    "1. **Importing Libraries**: We import the necessary libraries including `openai` for interacting with the Azure OpenAI API and `dotenv` for loading environment variables from a `.env` file.\n",
    "2. **Loading Environment Variables**: We load the API key, API version, and Azure endpoint from the `.env` file using `load_dotenv()` to ensure secure and dynamic configuration.\n",
    "3. **Initializing Azure Client**: We create an instance of the `AzureOpenAI` client using the loaded environment variables.\n",
    "4. **Environment Check**: To verify that everything is set up properly, we print the API key, version, and endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "import json\n",
    "import re\n",
    "import PyPDF2 \n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('variables.env')\n",
    "# Azure OpenAI configuration\n",
    "azure_openai_api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "azure_openai_api_version = os.getenv('AZURE_OPENAI_API_VERSION')\n",
    "azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "service_name = os.getenv('AZURE_SERVICE_NAME') \n",
    "admin_key = os.getenv('AZURE_ADMIN_KEY')  \n",
    "endpoint = f\"https://{service_name}.search.windows.net\"\n",
    "openai_deployment = \"gpt-4o\"  # Replace with your model deployment name\n",
    "\n",
    "print(azure_openai_api_key)\n",
    "print(azure_openai_api_version)\n",
    "print(azure_endpoint)\n",
    "print(service_name)\n",
    "print(admin_key)\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ai Search Index Creation\n",
    "\n",
    "This cell creates an Azure Cognitive Search index for climate change documents.\n",
    "\n",
    "Key points:\n",
    "- Sets up index schema with fields for id, content, and chapter\n",
    "- Uses REST API to create the index\n",
    "- Prints success message if index is created, error details if it fails\n",
    "\n",
    "Note: Ensure `admin_key` and `endpoint` are correctly set before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Previous code remains unchanged]\n",
    "\n",
    "# TODO: Complete the index schema\n",
    "index_schema = {\n",
    "    \"name\": index_name,\n",
    "    \"fields\": [\n",
    "        {\"name\": \"id\", \"type\": \"Edm.String\", \"key\": True, \"filterable\": True},\n",
    "        {\"name\": \"content\", \"type\": # Your code here},\n",
    "        {\"name\": \"chapter\", \"type\": # Your code here}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# HINT: For the 'content' field, consider using type \"Edm.String\" and making it searchable.\n",
    "# For the 'chapter' field, you might want to make it filterable and facetable.\n",
    "\n",
    "# [REST API call remains unchanged]\n",
    "\n",
    "# TODO: Add code to check the response status and print appropriate message\n",
    "if response.status_code == # Your code here:\n",
    "    print(# Your code here)\n",
    "else:\n",
    "    print(# Your code here)\n",
    "\n",
    "# HINT: Use response.status_code to check if the request was successful (status code 200 or 201).\n",
    "# Print a success message if the index was created, or an error message with response.text if it failed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Text Extraction\n",
    "\n",
    "This cell extracts text from a PDF file using PyPDF2.\n",
    "\n",
    "Key operations:\n",
    "- Defines a function to read and extract text from PDF\n",
    "- Extracts text from \"Understanding_Climate_Change.pdf\"\n",
    "- Prints a preview of the extracted text (first 500 characters)\n",
    "- Saves the full extracted text to \"extracted_text.txt\"\n",
    "\n",
    "Note: Ensure the PDF file path is correct before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in # Your code here:\n",
    "            text += # Your code here\n",
    "    return text\n",
    "\n",
    "# HINT: Use a for loop to iterate through reader.pages. For each page, use the extract_text() method and append the result to the text variable.\n",
    "\n",
    "# [PDF extraction code remains unchanged]\n",
    "\n",
    "# TODO: Save the extracted text to a file named 'extracted_text.txt'\n",
    "with open(\"extracted_text.txt\", \"w\", encoding=\"utf-8\") as # Your code here:\n",
    "    # Your code here\n",
    "\n",
    "# HINT: Use the with open() statement in write mode ('w') and the write() method to save the text to a file.\n",
    "# Don't forget to specify the encoding as 'utf-8' to handle special characters correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Chunking and Document Upload\n",
    "\n",
    "This cell processes the extracted PDF text and uploads it to Azure Cognitive Search.\n",
    "\n",
    "Key operations:\n",
    "- Chunks the content into smaller segments\n",
    "- Extracts chapter information\n",
    "- Creates documents with ID, content, and chapter\n",
    "- Uploads the documents to the search index\n",
    "\n",
    "Note: Ensure the 'content' variable contains the actual PDF text before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_content(text, max_chunk_size=5000):\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    for line in # Your code here:\n",
    "        if len(current_chunk) + len(line) > max_chunk_size:\n",
    "            chunks.append(# Your code here)\n",
    "            current_chunk = # Your code here\n",
    "        else:\n",
    "            current_chunk += # Your code here\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    return chunks\n",
    "\n",
    "# HINT: Split the text into lines and iterate through them. Add lines to the current_chunk until it reaches max_chunk_size, then append it to chunks and start a new current_chunk.\n",
    "\n",
    "def extract_chapters(text):\n",
    "    return re.findall(# Your code here)\n",
    "\n",
    "# HINT: Use re.findall() with a pattern like r'Chapter \\d+: .+' to find chapter titles in the text.\n",
    "\n",
    "# [Code to read content from file remains unchanged]\n",
    "\n",
    "documents = []\n",
    "for i, chunk in enumerate(chunked_content):\n",
    "    chapter = next((ch for ch in chapters if ch in chunk), \"Unknown Chapter\")\n",
    "    doc = {\n",
    "        \"id\": f\"doc{i}\",\n",
    "        \"content\": # Your code here,\n",
    "        \"chapter\": # Your code here\n",
    "    }\n",
    "    documents.append(doc)\n",
    "\n",
    "# HINT: Iterate through chunked_content, creating a dictionary for each chunk with 'id', 'content', and 'chapter' keys. Append each dictionary to the documents list.\n",
    "\n",
    "# [Upload API call remains unchanged]\n",
    "\n",
    "# TODO: Check response status and print appropriate message\n",
    "if response.status_code == # Your code here:\n",
    "    print(f\"Successfully uploaded {# Your code here} documents.\")\n",
    "else:\n",
    "    print(# Your code here)\n",
    "\n",
    "# HINT: Check response.status_code. If it's 200 or 201, print a success message with the number of documents uploaded. Otherwise, print an error message with response.text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Verification\n",
    "\n",
    "This cell verifies the content uploaded to Azure Cognitive Search.\n",
    "\n",
    "Key operations:\n",
    "- Defines functions to:\n",
    "  - Get total document count\n",
    "  - Retrieve a sample of documents\n",
    "- Prints total document count\n",
    "- Displays sample documents with ID and chapter\n",
    "\n",
    "Note: This helps confirm successful upload and indexing of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_count():\n",
    "    count_url = f\"{endpoint}/indexes/{index_name}/docs/$count?api-version=2020-06-30\"\n",
    "    response = requests.get(# Your code here)\n",
    "    if response.status_code == 200:\n",
    "        return int(# Your code here)\n",
    "    else:\n",
    "        print(f\"Failed to get document count. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# HINT: Use requests.get() to make the API call. If successful, return int(response.text). Handle potential errors and return None if the call fails.\n",
    "\n",
    "def get_sample_documents(sample_size=5):\n",
    "    search_url = f\"{endpoint}/indexes/{index_name}/docs?api-version=2020-06-30\"\n",
    "    params = {\n",
    "        'search': '*',\n",
    "        'top': sample_size,\n",
    "        'select': 'id,chapter'\n",
    "    }\n",
    "    response = requests.get(# Your code here)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[# Your code here]\n",
    "    else:\n",
    "        print(f\"Failed to get sample documents. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# HINT: Use requests.get() with the search_url and params. If successful, return response.json()['value']. Handle potential errors and return None if the call fails.\n",
    "\n",
    "# [Code to get document count and sample documents remains unchanged]\n",
    "\n",
    "if sample_docs:\n",
    "    print(\"\\nSample documents:\")\n",
    "    for doc in sample_docs:\n",
    "        print(f\"ID: {doc[# Your code here]}, Chapter: {doc[# Your code here]}\")\n",
    "\n",
    "# HINT: Use a for loop to iterate through sample_docs. For each document, print its 'id' and 'chapter' values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Search and Results Display\n",
    "\n",
    "This cell demonstrates searching the Azure Cognitive Search index.\n",
    "\n",
    "Key operations:\n",
    "- Defines a function to search documents with highlighting\n",
    "- Performs test searches on climate change topics\n",
    "- Displays search results including:\n",
    "  - Document ID\n",
    "  - Chapter\n",
    "  - Highlighted relevant content\n",
    "\n",
    "Note: This showcases the search functionality and result presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents(query, top=3):\n",
    "    search_url = f\"{endpoint}/indexes/{index_name}/docs/search?api-version=2020-06-30\"\n",
    "    body = {\n",
    "        \"search\": query,\n",
    "        \"top\": top,\n",
    "        \"select\": \"id,chapter,content\",\n",
    "        \"highlight\": \"content\"\n",
    "    }\n",
    "    response = requests.post(# Your code here)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[# Your code here]\n",
    "    else:\n",
    "        print(f\"Search failed. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# HINT: Use requests.post() with the search_url, headers, and body. If successful, return response.json()['value']. Handle potential errors and return an empty list if the call fails.\n",
    "\n",
    "# [Test searches code remains unchanged]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nSearching for: {query}\")\n",
    "    results = search_documents(query)\n",
    "    if results:\n",
    "        for result in results:\n",
    "            print(f\"ID: {result[# Your code here]}\")\n",
    "            print(f\"Chapter: {result[# Your code here]}\")\n",
    "            print(f\"Highlighted content: {result.get('@search.highlights', {}).get('content', ['No highlight'])[0]}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"No results found.\")\n",
    "\n",
    "# HINT: For each result, print the 'id' and 'chapter'. For the highlighted content, access result.get('@search.highlights', {}).get('content', ['No highlight'])[0]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Rechunking and Reindexing\n",
    "\n",
    "This cell improves the document chunking process and reindexes the content.\n",
    "\n",
    "Key operations:\n",
    "- Redefines chunking function to preserve chapter information\n",
    "- Loads extracted PDF text from file\n",
    "- Creates new documents with improved chapter tracking\n",
    "- Uploads rechunked documents to the search index\n",
    "\n",
    "Note: This process enhances the organization and searchability of the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def chunk_content(text, max_chunk_size=5000):\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    current_chapter = \"Unknown Chapter\"\n",
    "    \n",
    "    for line in text.split('\\n'):\n",
    "        if line.strip().startswith(\"Chapter\"):\n",
    "            if current_chunk:\n",
    "                chunks.append((# Your code here))\n",
    "            current_chunk = # Your code here\n",
    "            current_chapter = # Your code here\n",
    "        elif len(current_chunk) + len(line) > max_chunk_size:\n",
    "            chunks.append((# Your code here))\n",
    "            current_chunk = # Your code here\n",
    "        else:\n",
    "            current_chunk += # Your code here\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append((# Your code here))\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# HINT: When appending to chunks, use (current_chapter, current_chunk.strip())\n",
    "# For the 'else' case, remember to add a space before the new line\n",
    "\n",
    "# Load the extracted PDF text\n",
    "with open(\"extracted_text.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    pdf_content = file.read()\n",
    "\n",
    "chunked_content = chunk_content(# Your code here)\n",
    "\n",
    "documents = []\n",
    "for i, (chapter, chunk) in enumerate(chunked_content):\n",
    "    doc = {\n",
    "        \"id\": f\"doc{i}\",\n",
    "        \"content\": # Your code here,\n",
    "        \"chapter\": # Your code here\n",
    "    }\n",
    "    documents.append(doc)\n",
    "\n",
    "# HINT: Use the 'chunk' and 'chapter' variables to fill in the 'content' and 'chapter' fields of the doc dictionary\n",
    "\n",
    "# Upload documents\n",
    "upload_url = f\"{endpoint}/indexes/{index_name}/docs/index?api-version=2020-06-30\"\n",
    "response = requests.post(upload_url, headers=headers, json={\"value\": documents})\n",
    "\n",
    "if response.status_code == # Your code here:\n",
    "    print(f\"Successfully reindexed {# Your code here} documents.\")\n",
    "else:\n",
    "    print(f\"Failed to reindex documents. Status code: {response.status_code}\")\n",
    "    print(# Your code here)\n",
    "\n",
    "# HINT: Check if the status code is 200 for a successful request\n",
    "# Use len(documents) to get the number of reindexed documents\n",
    "# Print response.text in case of an error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Pipeline Implementation\n",
    "\n",
    "This cell implements a Retrieval-Augmented Generation (RAG) pipeline for climate change questions.\n",
    "\n",
    "Key components:\n",
    "- Document retrieval from Azure Cognitive Search\n",
    "- Prompt creation using retrieved documents\n",
    "- Response generation using Azure OpenAI\n",
    "\n",
    "Features:\n",
    "- Utilizes both search and OpenAI APIs\n",
    "- Creates context-aware prompts\n",
    "- Implements an interactive Q&A loop\n",
    "\n",
    "Note: Ensure all API keys and endpoints are correctly set before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Headers setup remains unchanged]\n",
    "\n",
    "def retrieve_documents(query: str, top: int = 3) -> List[Dict]:\n",
    "    return search_documents(# Your code here)\n",
    "\n",
    "# HINT: Use the search_documents() function you created earlier, passing the query and top parameters.\n",
    "\n",
    "def create_prompt(query: str, docs: List[Dict]) -> str:\n",
    "    context = \"\\n\\n\".join([f\"Chapter: {doc['chapter']}\\nContent: {doc['content']}\" for doc in docs])\n",
    "    return f\"\"\"You are an AI assistant specializing in climate change. Use the following information to answer the user's question. If you can't answer the question based on the provided information, say so.\n",
    "\n",
    "Context:\n",
    "{# Your code here}\n",
    "\n",
    "User Question: {# Your code here}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "# HINT: Construct a string that includes context from the documents and the user's query. Consider using f-strings to format the prompt.\n",
    "\n",
    "def generate_response(prompt: str) -> str:\n",
    "    url = f\"{azure_endpoint}/openai/deployments/{openai_deployment}/chat/completions?api-version=2023-05-15\"\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions about climate change.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": 150,\n",
    "        \"temperature\": 0.7,\n",
    "        \"n\": 1\n",
    "    }\n",
    "    response = requests.post(# Your code here)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['choices'][0]['message'][# Your code here]\n",
    "    else:\n",
    "        print(f\"OpenAI API request failed. Status code: {response.status_code}\")\n",
    "        return \"Sorry, I couldn't generate a response at this time.\"\n",
    "\n",
    "# HINT: Use requests.post() with the url, headers, and json payload. Extract and return the generated text from the response JSON.\n",
    "\n",
    "def rag_pipeline(query: str) -> str:\n",
    "    docs = retrieve_documents(# Your code here)\n",
    "    prompt = create_prompt(# Your code here)\n",
    "    response = generate_response(# Your code here)\n",
    "    return response\n",
    "\n",
    "# HINT: Call retrieve_documents(), then create_prompt() with the retrieved documents, and finally generate_response() with the created prompt.\n",
    "\n",
    "# [Example usage code remains unchanged]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced RAG Pipeline with Customization Options\n",
    "\n",
    "This cell implements an advanced Retrieval-Augmented Generation (RAG) pipeline for climate change queries.\n",
    "\n",
    "Key features:\n",
    "- Flexible document retrieval from Azure Cognitive Search\n",
    "- Customizable prompt styles (default, detailed, concise)\n",
    "- Adjustable response length with max_tokens\n",
    "- Interactive user input for query parameters\n",
    "\n",
    "Components:\n",
    "- Document retrieval function\n",
    "- Dynamic prompt creation based on style\n",
    "- Azure OpenAI integration for response generation\n",
    "- Main loop for continuous user interaction\n",
    "\n",
    "Note: Ensure all API keys and endpoints are correctly configured before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'api-key': admin_key\n",
    "}\n",
    "\n",
    "openai_headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'api-key': azure_openai_api_key\n",
    "}\n",
    "\n",
    "def retrieve_documents(query: str, top: int = 3) -> List[Dict]:\n",
    "    search_url = f\"{endpoint}/indexes/{index_name}/docs/search?api-version=2020-06-30\"\n",
    "    body = {\n",
    "        \"search\": query,\n",
    "        \"top\": top,\n",
    "        \"select\": \"content,chapter\",\n",
    "        \"highlight\": \"content\"\n",
    "    }\n",
    "    response = requests.post(# Your code here)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[# Your code here]\n",
    "    else:\n",
    "        print(f\"Search failed. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# HINT: Use the search_url, headers, and body for the POST request. Return the 'value' key from the JSON response.\n",
    "\n",
    "def create_prompt(query: str, docs: List[Dict], prompt_style: str = \"default\") -> str:\n",
    "    context = \"\\n\\n\".join([f\"Chapter: {doc['chapter']}\\nContent: {doc['content']}\" for doc in docs])\n",
    "    \n",
    "    if prompt_style == \"detailed\":\n",
    "        return f\"\"\"You are an AI assistant specializing in climate change. Use the following information to answer the user's question. If you can't answer the question based on the provided information, say so. Provide a detailed explanation and, if possible, include specific examples or data from the context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User Question: {query}\n",
    "\n",
    "Detailed Answer:\"\"\"\n",
    "    \n",
    "    elif prompt_style == \"concise\":\n",
    "        return f\"\"\"You are an AI assistant specializing in climate change. Provide a brief and concise answer to the user's question based on the following information. If you can't answer the question based on the provided information, say so briefly.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User Question: {query}\n",
    "\n",
    "Concise Answer:\"\"\"\n",
    "    \n",
    "    else:  # default prompt style\n",
    "        return # Your code here\n",
    "\n",
    "# HINT: For the default prompt style, use a format similar to the \"detailed\" and \"concise\" styles, but with a balance between detail and brevity.\n",
    "\n",
    "def generate_response(prompt: str, max_tokens: int = 150) -> str:\n",
    "    url = f\"{azure_endpoint}/openai/deployments/{openai_deployment}/chat/completions?api-version=2023-05-15\"\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions about climate change.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": 0.7,\n",
    "        \"n\": 1\n",
    "    }\n",
    "    response = requests.post(# Your code here)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['choices'][0]['message'][# Your code here]\n",
    "    else:\n",
    "        print(f\"OpenAI API request failed. Status code: {response.status_code}\")\n",
    "        return \"Sorry, I couldn't generate a response at this time.\"\n",
    "\n",
    "# HINT: Use the url, headers, and json payload for the POST request. Return the 'content' of the generated message.\n",
    "\n",
    "def rag_pipeline(query: str, num_docs: int = 3, prompt_style: str = \"default\", max_tokens: int = 150) -> str:\n",
    "    docs = retrieve_documents(# Your code here)\n",
    "    prompt = create_prompt(# Your code here)\n",
    "    response = generate_response(# Your code here)\n",
    "    return response\n",
    "\n",
    "# HINT: Pass the appropriate parameters to each function call in the pipeline.\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        user_query = input(\"Enter your question about climate change (or 'quit' to exit): \")\n",
    "        if user_query.lower() == 'quit':\n",
    "            break\n",
    "        \n",
    "        num_docs = int(input(\"Enter the number of documents to retrieve (1-5): \"))\n",
    "        prompt_style = input(\"Enter prompt style (default/detailed/concise): \")\n",
    "        max_tokens = int(input(\"Enter maximum number of tokens for the response (50-500): \"))\n",
    "        \n",
    "        answer = rag_pipeline(# Your code here)\n",
    "        print(f\"\\nAnswer: {answer}\\n\")\n",
    "\n",
    "# HINT: Pass all the user inputs to the rag_pipeline function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
